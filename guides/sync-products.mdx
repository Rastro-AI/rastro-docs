---
title: 'Sync Products'
description: 'Keep your catalog in sync with external systems'
---

## Overview

Sync products from your database, ERP, or other systems to Rastro using the bulk upsert endpoint.

## Basic Sync Pattern

```python
import requests

API_KEY = "rastro_pk_..."
BASE_URL = "https://catalogapi.rastro.ai/api"
CATALOG_ID = "your_catalog_id"

headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

def sync_products(products):
    """Sync products to Rastro."""
    response = requests.post(
        f"{BASE_URL}/public/catalogs/{CATALOG_ID}/items/bulk",
        headers=headers,
        json={
            "items": products,
            "unique_field": "sku"
        }
    )
    return response.json()

# Example
products = [
    {"sku": "A001", "title": "Product A", "price": 29.99},
    {"sku": "A002", "title": "Product B", "price": 39.99},
]

result = sync_products(products)
print(f"Created: {result['created']}, Updated: {result['updated']}")
```

## Sync from Database

```python
import psycopg2
import requests

# Fetch from your database
conn = psycopg2.connect("postgresql://...")
cursor = conn.cursor()
cursor.execute("""
    SELECT sku, name, price, description, category
    FROM products
    WHERE updated_at > NOW() - INTERVAL '1 hour'
""")

products = [
    {
        "sku": row[0],
        "title": row[1],
        "price": row[2],
        "description": row[3],
        "category": row[4]
    }
    for row in cursor.fetchall()
]

# Sync to Rastro
if products:
    result = sync_products(products)
    print(f"Synced {len(products)} products")
```

## Sync from CSV

```python
import csv

with open("products.csv") as f:
    products = list(csv.DictReader(f))

# Sync in batches
batch_size = 500
for i in range(0, len(products), batch_size):
    batch = products[i:i+batch_size]
    result = sync_products(batch)
    print(f"Batch {i//batch_size + 1}: {result}")
```

## Scheduled Sync

Run sync on a schedule using cron or a task scheduler:

```python
# sync_job.py
import schedule
import time

def daily_sync():
    products = fetch_products_from_source()
    result = sync_products(products)
    print(f"Daily sync: {result}")

schedule.every().day.at("02:00").do(daily_sync)

while True:
    schedule.run_pending()
    time.sleep(60)
```

## Handling Large Datasets

For catalogs with >1000 items, paginate your syncs:

```python
def sync_all_products(products, batch_size=500):
    total = {"created": 0, "updated": 0, "failed": 0}

    for i in range(0, len(products), batch_size):
        batch = products[i:i+batch_size]
        result = sync_products(batch)

        total["created"] += result["created"]
        total["updated"] += result["updated"]
        total["failed"] += result.get("failed", 0)

        print(f"Progress: {min(i+batch_size, len(products))}/{len(products)}")

    return total
```
