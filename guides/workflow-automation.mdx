---
title: 'Workflow Automation'
description: 'Run AI workflows programmatically'
---

## Overview

Execute Rastro workflows via API to automate data enrichment.

## Basic Pattern

```python
import requests
import time

API_KEY = "rastro_pk_..."
BASE_URL = "https://catalogapi.rastro.ai/api"

headers = {"Authorization": f"Bearer {API_KEY}"}

def run_workflow(workflow_id, input_data):
    """Execute workflow and return results."""

    # Start
    response = requests.post(
        f"{BASE_URL}/public/workflows/{workflow_id}/execute",
        headers={**headers, "Content-Type": "application/json"},
        json={"input": input_data}
    )
    run_id = response.json()["workflow_run_id"]

    # Poll
    while True:
        status = requests.get(
            f"{BASE_URL}/public/workflows/runs/{run_id}",
            headers=headers
        ).json()

        if status["status"] == "completed":
            return status["results"]["data"]
        if status["status"] == "failed":
            raise Exception(status["message"])

        time.sleep(3)
```

## Enrich Products

```python
# Products to enrich
products = [
    {"sku": "LAPTOP-001", "title": "Pro Laptop 15\""},
    {"sku": "LAPTOP-002", "title": "Gaming Laptop 17\""},
]

# Run enrichment workflow
enriched = run_workflow("your_workflow_id", products)

# Update catalog with enriched data
requests.post(
    f"{BASE_URL}/public/catalogs/{catalog_id}/items/bulk",
    headers={**headers, "Content-Type": "application/json"},
    json={"items": enriched, "unique_field": "sku"}
)
```

## Batch Processing

Process large datasets in chunks:

```python
def process_in_batches(products, workflow_id, batch_size=50):
    """Process products through workflow in batches."""
    all_results = []

    for i in range(0, len(products), batch_size):
        batch = products[i:i+batch_size]
        print(f"Processing batch {i//batch_size + 1}")

        results = run_workflow(workflow_id, batch)
        all_results.extend(results)

    return all_results
```

## Error Handling

```python
def run_workflow_safe(workflow_id, input_data, max_retries=3):
    """Execute workflow with retry logic."""

    for attempt in range(max_retries):
        try:
            return run_workflow(workflow_id, input_data)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            print(f"Attempt {attempt + 1} failed, retrying...")
            time.sleep(5 * (attempt + 1))
```

## Webhook Integration

Instead of polling, you can set up webhooks in the dashboard to receive notifications when workflows complete.
